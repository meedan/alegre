IMAGE_MODEL=phash
OPENSEARCH_URL=http://opensearch:9200
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DATABASE=0
DATABASE_NAME=alegre
DATABASE_HOST=postgres
DATABASE_USER=postgres
DATABASE_PASS=postgres

# Exception reporting using Airbrake or compatible API
#
# OPTIONAL
#
AIRBRAKE_URL=
AIRBRAKE_PROJECT_KEY=
AIRBRAKE_ENVIRONMENT=

# Language identification provider
#
# REQUIRED
# Provider can be `google` or `microsoft`, as per ./app/main/lib/langid.py
# - Google Cloud Translation API (Basic) https://cloud.google.com/translate
#   Requires a `./google_credentials.json` file as per https://cloud.google.com/docs/authentication/getting-started
# - Microsoft Text Analytics API https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/
#   Requires the MS_TEXT_ANALYTICS_XXX keys below
#
PROVIDER_LANGID=google

# OpenAI API_Key
#
# REQUIRED to produce vector embeddings using an OpenAI model
# For local development, you can populate this key from SSM.
# The key is /local/alegre/OPENAI_API_KEY
#
OPENAI_API_KEY=

# Microsoft Text Analytics API
#
# REQUIRED if PROVIDER_LANGID is set to `microsoft`
#
MS_TEXT_ANALYTICS_KEY=<MICROSOFT TEXT ANALYTICS SUBSCRIPTION KEY>
MS_TEXT_ANALYTICS_URL=https://westcentralus.api.cognitive.microsoft.com/text/analytics/v2.1/

# Image classification provider
#
# REQUIRED
# Provider can only be `google`, as per ./app/main/lib/image_classification.py
# - Google Vision API https://cloud.google.com/vision/
#   Requires a `./google_credentials.json` file as per https://cloud.google.com/docs/authentication/getting-started
#
PROVIDER_IMAGE_CLASSIFICATION=google

# AWS Credentials for audio transcription
#
# Get the AWS environment variables for command line or programmatic access
#
# REQUIRED
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_SESSION_TOKEN=


# Service host URLs
PRESTO_HOST=http://presto:8000
ALEGRE_HOST=http://alegre:3100
CHECK_API_HOST=http://api:3000
WEBHOOK_TOKEN=dev
